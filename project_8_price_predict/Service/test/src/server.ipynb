{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сервис предсказания стоимости объектов недвижимости с использованием полученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import json\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Контроль доступности сервиса\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'Test message. The server is running'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "import ast\n",
    "#from Model.ms_func import Dumper\n",
    "import pickle\n",
    "from os import path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Класс для чтения сохранённой модели и вспомогательных данных\n",
    "class Dumper():  \n",
    "    def __init__(self, model_dir=\"Model/\"):  \n",
    "        self.model_dir = model_dir  \n",
    "          \n",
    "    # сохраняет объект\n",
    "    def dump(self, data, filename):  \n",
    "        with open(self.get_file_name(filename), 'wb') as file:  \n",
    "            pickle.dump(data, file)  \n",
    "              \n",
    "    # загружает объект\n",
    "    def load(self, filename):  \n",
    "        file_name = path.join(self.model_dir, filename + \".pkl\")   \n",
    "        with open(file_name, 'rb') as file:  \n",
    "            sets = pickle.load(file)  \n",
    "        return sets  \n",
    "          \n",
    "    # возвращает полное имя файла\n",
    "    def get_file_name(self, filename):   \n",
    "        return path.join(self.model_dir, filename + \".pkl\")\n",
    "    \n",
    "app_geo = Nominatim(user_agent=\"tutorial\")\n",
    "    \n",
    "def get_loc(street, city, zipcode):\n",
    "    \"\"\"Получаем географические координаты по адресу, городу, почтовому индексу\n",
    "\n",
    "    Args:\n",
    "        street (string): адрес\n",
    "        city (string): город\n",
    "        zipcode (string): почтовый индекс\n",
    "\n",
    "    Returns:\n",
    "        tuple (float lat, float lon): географические координаты.\n",
    "    \"\"\"\n",
    "    answ = (np.nan, np.nan)\n",
    "    if street == None:\n",
    "        street = ''\n",
    "    if city == None:\n",
    "        city = ''\n",
    "    if zipcode == None:\n",
    "        zipcode = ''\n",
    "    street = str(street).strip()\n",
    "    city = str(city).strip()\n",
    "    zipcode = str(zipcode).strip()\n",
    "    haserror = False\n",
    "    \n",
    "    try:\n",
    "        location = app_geo.geocode(street + ' ' + city).raw\n",
    "        answ = (location['lat'], location['lon'])\n",
    "    except Exception:\n",
    "        haserror = True\n",
    "        \n",
    "    if haserror == True:\n",
    "        try:\n",
    "            location = app_geo.geocode(zipcode).raw\n",
    "            answ = (location['lat'], location['lon'])\n",
    "        except Exception:\n",
    "            answ = (np.nan, np.nan)\n",
    "    \n",
    "    return answ\n",
    "\n",
    "def GetFromHomeFactsList(AStr):\n",
    "    \"\"\"Получить информацию из записи в колонке homeFacts\n",
    "\n",
    "    Args:\n",
    "        string: строка из колокни homeFacts.\n",
    "\n",
    "    Returns:\n",
    "        list: значения свойств: 'Year built', 'Remodeled year', 'Heating', 'Cooling', 'Parking', 'lotsize', 'Price/sqft'\n",
    "    \"\"\"\n",
    "    answ = [None, None, None, None, None, None, None]\n",
    "    labs = ['Year built', 'Remodeled year', 'Heating', 'Cooling', 'Parking', 'lotsize', 'Price/sqft']\n",
    "    try:\n",
    "        lst = ast.literal_eval(AStr)['atAGlanceFacts']\n",
    "        answ = []\n",
    "        for l in labs:\n",
    "            fnd = False\n",
    "            try:\n",
    "                for val in lst:\n",
    "                    if val['factLabel'] == l:\n",
    "                        answ.append(val['factValue'])\n",
    "                        fnd = True\n",
    "                        break\n",
    "                if fnd == False:\n",
    "                    answ.append(None)\n",
    "            except Exception:\n",
    "                answ.append(None)\n",
    "    except Exception:\n",
    "        return answ\n",
    "    return answ\n",
    "\n",
    "def GetFromSchoolList(AStr):\n",
    "    \"\"\"Получить информацию из записи в колонке schools\n",
    "\n",
    "    Args:\n",
    "        string: строка из колокни schools.\n",
    "\n",
    "    Returns:\n",
    "        list: значения свойств: 'rating', 'data'.'Distance', 'data'.'Grades', 'name'\n",
    "    \"\"\"\n",
    "    answ = [[None], [None], [None], [None]]\n",
    "    labs1lvl = ['rating', 'data', 'name']\n",
    "    labs2lvl = ['Distance', 'Grades']\n",
    "    try:\n",
    "        lst = ast.literal_eval(AStr)[0]\n",
    "        answ = []\n",
    "        for l in labs1lvl:\n",
    "            try:\n",
    "                if l == 'data':\n",
    "                    try:\n",
    "                        answ.append(lst[l]['Distance'])    \n",
    "                    except Exception:\n",
    "                        answ.append([None])\n",
    "                    try:\n",
    "                        answ.append(lst[l]['Grades'])    \n",
    "                    except Exception:\n",
    "                        answ.append([None])\n",
    "                else:\n",
    "                    answ.append(lst[l])  \n",
    "            except Exception:\n",
    "                answ.append([None])\n",
    "    except Exception:\n",
    "        return answ\n",
    "    return answ\n",
    "\n",
    "def strIntersection(s1, s2):\n",
    "    \"\"\"Служебная функция для того, чтобы оставлять в строке только те символы, которые соответствуют маске\n",
    "\n",
    "    Args:\n",
    "        string: s1 исходная строка.\n",
    "        string: s2 маска.\n",
    "\n",
    "    Returns:\n",
    "        string: исходная строка после применения маски\n",
    "    \"\"\"\n",
    "    out = \"\"\n",
    "    for c in s1:\n",
    "        if c in s2:\n",
    "            out += c\n",
    "    return out\n",
    "\n",
    "def MaxMinMeanDistance(Alst):\n",
    "    \"\"\"Функция для определения минимального, максимального и среднего расстояния до учебного заведения\n",
    "\n",
    "    Args:\n",
    "        list: Alst - список из расстояний.\n",
    "\n",
    "    Returns:\n",
    "        list: минимальное, максимальное и среднее расстояние до учебного заведения\n",
    "    \"\"\"\n",
    "    res = [np.nan, np.nan, np.nan]\n",
    "    dcount = 0\n",
    "    dsum = 0.0\n",
    "    dMax = 0.0\n",
    "    dMin = np.inf\n",
    "    mask = '0123456789.'\n",
    "    for elm in Alst:\n",
    "        elm = strIntersection(elm, mask)\n",
    "        if elm != '':\n",
    "            fElm = float(elm)\n",
    "            dsum += fElm\n",
    "            if fElm < dMin:\n",
    "                dMin = fElm\n",
    "            if fElm > dMax:\n",
    "                dMax = fElm\n",
    "            dcount += 1\n",
    "    if dcount > 0:\n",
    "        res = [dMax, dMin, dsum/dcount]\n",
    "    return res\n",
    "\n",
    "def MaxMinMeanRating(Alst):\n",
    "    \"\"\"Функция для определения минимального, максимального и среднего рейтинга учебного заведения\n",
    "\n",
    "    Args:\n",
    "        list: Alst - список рейтингов.\n",
    "\n",
    "    Returns:\n",
    "        list: минимальное, максимальное и среднее значение рейтинга учебного заведения\n",
    "    \"\"\"\n",
    "    res = [np.nan, np.nan, np.nan]\n",
    "    dcount = 0\n",
    "    dsum = 0.0\n",
    "    dMax = 0.0\n",
    "    dMin = np.inf\n",
    "    mask = '0123456789/'\n",
    "    for elm in Alst:\n",
    "        elm = strIntersection(elm, mask)\n",
    "        elm = elm.replace('/10', '')\n",
    "        if elm != '':\n",
    "            fElm = float(elm)\n",
    "            dsum += fElm\n",
    "            if fElm < dMin:\n",
    "                dMin = fElm\n",
    "            if fElm > dMax:\n",
    "                dMax = fElm\n",
    "            dcount += 1\n",
    "    if dcount > 0:\n",
    "        res = [dMax/10, dMin/10, dsum/dcount/10]\n",
    "    return res\n",
    "\n",
    "def str_to_float(aStr):\n",
    "    \"\"\"Функция для преобразования строки в действительное число\n",
    "\n",
    "    Args:\n",
    "        string: aStr - возможное число в строковом представлении\n",
    "\n",
    "    Returns:\n",
    "        float: действительное число или nan, если не удалось совершить преобразование\n",
    "    \"\"\"\n",
    "    if aStr == None:\n",
    "        return np.nan\n",
    "    aStr = strIntersection(str(aStr), '-0123456789.')\n",
    "    if aStr == '':\n",
    "        return np.nan\n",
    "    aStr = aStr.replace('..', '.')\n",
    "    aStr = aStr.replace('--', '-')\n",
    "    if aStr == '.':\n",
    "        return np.nan\n",
    "    if aStr[len(aStr) - 1] == '.':\n",
    "        aStr = aStr[0:len(aStr)-1]\n",
    "    try:\n",
    "        return float(aStr)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def str_float_to_int(aStr):\n",
    "    \"\"\"Функция для преобразования строки в целое число\n",
    "\n",
    "    Args:\n",
    "        string: aStr - возможное число в строковом представлении\n",
    "\n",
    "    Returns:\n",
    "        float: целое число или nan, если не удалось совершить преобразование\n",
    "    \"\"\"\n",
    "    aFlt = str_to_float(aStr)\n",
    "    try:\n",
    "        return int(round(aFlt))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    \n",
    "def ColToLow(df, colname):\n",
    "    \"\"\"Функция для приведения текстового признака к нижнему регистру и только базовым символам\n",
    "\n",
    "    Args:\n",
    "        dataframe: df - исходный датафрейм\n",
    "        string: colname - признак\n",
    "\n",
    "    Returns:\n",
    "        преобразует признак в исходном датафрейме\n",
    "    \"\"\"\n",
    "    mask = 'qwertyuiopasdfghjklzxcvbnm1234567890'\n",
    "    df[colname] = df[colname].str.lower()\n",
    "    df[colname] = df[colname].apply(lambda x: strIntersection(str(x), mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumper = Dumper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/al/.local/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DummyRegressor from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/al/.local/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/al/.local/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GradientBoostingRegressor from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/al/.local/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/al/.local/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator QuantileTransformer from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# модель\n",
    "model = dumper.load('model')\n",
    "# граничный коэффициент ванн на квадратный фут\n",
    "bath_sqft_border_coef = dumper.load('bath_sqft_border_coef')\n",
    "# среднее количество ванн на квадратный фут\n",
    "bath_sqft_coef = dumper.load('bath_sqft_coef')\n",
    "# географический прямоугольник, ограничивающий координаты объектов в США\n",
    "geo_borders = dumper.load('geo_borders')\n",
    "# медианные значения ключевых признаков в Калифонии (CA)\n",
    "median_CA = dumper.load('median_CA')\n",
    "# медианные значения ключевых признаков в остальных штатах\n",
    "median_other = dumper.load('median_other')\n",
    "# преобразователь масштаба\n",
    "scaler = dumper.load('scaler')\n",
    "# преобразователь QuantileTransformer\n",
    "sqft_q_trans = dumper.load('sqft_q_trans')\n",
    "# список колонок (и их порядок), которые участвуют в финальных признаках\n",
    "df_columns = dumper.load('df_columns')\n",
    "# порядок сокращённого набора признаков\n",
    "idx10_features = dumper.load('idx10_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(adf):\n",
    "    \"\"\"Преобразовать входной dataframe в набор, котрый можно подать на вход модели\n",
    "       Преобразователь преобразует тип, заполняет, кодирует, масштабирует признаки аналогично тому, как это происходило при подготовке датасета модели\n",
    "\n",
    "    Args:\n",
    "        dataframe: датафрейм для прогнозирования.\n",
    "\n",
    "    Returns:\n",
    "        ndarray X: признаки, подготовленные к передаче в модель\n",
    "        series y: целевой признак (для проверки); если использование \"боевое\", то передать в исходном dataframe 0\n",
    "    \"\"\"\n",
    "    vdf = adf.copy()    \n",
    "      \n",
    "    vdf['SC_List'] = vdf['schools'].apply(lambda x: GetFromSchoolList(x))\n",
    "\n",
    "    vdf['SC_Distance'] = vdf['SC_List'].apply(lambda x: x[1])\n",
    "    vdf['SC_Distance_Lst'] = vdf['SC_Distance'].apply(lambda x: MaxMinMeanDistance(x))\n",
    "    vdf['SC_Distance_Max'] = vdf['SC_Distance_Lst'].apply(lambda x: x[0])\n",
    "    \n",
    "    vdf['SC_Rating'] = vdf['SC_List'].apply(lambda x: x[0])    \n",
    "    vdf['SC_Rating_Lst'] = vdf['SC_Rating'].apply(lambda x: MaxMinMeanRating(x))\n",
    "    vdf['SC_Rating_Mean'] = vdf['SC_Rating_Lst'].apply(lambda x: x[2])\n",
    "    \n",
    "    vdf['lat'], vdf['lng'] = zip(*vdf.apply(lambda x: get_loc(x['street'], x['city'], x['zipcode']), axis = 1))\n",
    "    vdf['lat'] = vdf['lat'].apply(lambda x: str_to_float(x))\n",
    "    vdf['lng'] = vdf['lng'].apply(lambda x: str_to_float(x))\n",
    "    \n",
    "    vdf['sqft'] = vdf['sqft'].apply(lambda x: str_float_to_int(x))\n",
    "    vdf['baths'] = vdf['baths'].apply(lambda x: str_float_to_int(x))\n",
    "    \n",
    "    vdf['HF_List'] = vdf['homeFacts'].apply(lambda x: GetFromHomeFactsList(x))\n",
    "    vdf['HF_YearBuilt'] = vdf['HF_List'].apply(lambda x: x[0])\n",
    "    vdf['HF_Lotsize'] = vdf['HF_List'].apply(lambda x: x[5])\n",
    "    vdf['HF_YearBuilt'] = vdf['HF_YearBuilt'].apply(lambda x: str_float_to_int(x))\n",
    "    vdf['HF_Lotsize'] = vdf['HF_Lotsize'].apply(lambda x: str_float_to_int(x))\n",
    "    vdf['target'] = vdf['target'].apply(lambda x: str_float_to_int(x))\n",
    "    \n",
    "    ColToLow(vdf, 'propertyType')\n",
    "    vdf['propertyType_condo'] = vdf['propertyType'].apply(lambda x: 1 if x == 'condo' else 0)\n",
    "    \n",
    "    vdf['state_CA'] = vdf['state'].apply(lambda x: 1 if x == 'CA' else 0)\n",
    "    \n",
    "    vdf['SC_Distance_Max'] = vdf.apply(lambda x: median_other['SC_Distance_Max'] if (np.isnan(x['SC_Distance_Max']) or (x['SC_Distance_Max'] == 0)) and (x['state_CA'] == 0)        \n",
    "        else x['SC_Distance_Max'], axis = 1)\n",
    "    vdf['SC_Distance_Max'] = vdf.apply(lambda x: median_CA['SC_Distance_Max'] if (np.isnan(x['SC_Distance_Max']) or (x['SC_Distance_Max'] == 0)) and (x['state_CA'] == 1)\n",
    "        else x['SC_Distance_Max'], axis = 1)\n",
    "    \n",
    "    vdf['SC_Rating_Mean'] = vdf.apply(lambda x: median_other['SC_Rating_Mean'] if (np.isnan(x['SC_Rating_Mean']) or (x['SC_Rating_Mean'] == 0)) and (x['state_CA'] == 0)        \n",
    "        else x['SC_Rating_Mean'], axis = 1)\n",
    "    vdf['SC_Rating_Mean'] = vdf.apply(lambda x: median_CA['SC_Rating_Mean'] if (np.isnan(x['SC_Rating_Mean']) or (x['SC_Rating_Mean'] == 0)) and (x['state_CA'] == 1)\n",
    "        else x['SC_Rating_Mean'], axis = 1)\n",
    "    \n",
    "    vdf['lat'] = vdf.apply(lambda x: median_other['lat'] if (np.isnan(x['lat']) or (x['lat'] < geo_borders['minlat']) or (x['lat'] > geo_borders['maxlat'])) and (x['state_CA'] == 0)\n",
    "        else x['lat'], axis = 1)\n",
    "    vdf['lat'] = vdf.apply(lambda x: median_CA['lat'] if (np.isnan(x['lat']) or (x['lat'] < geo_borders['minlat']) or (x['lat'] > geo_borders['maxlat'])) and (x['state_CA'] == 1)\n",
    "        else x['lat'], axis = 1)\n",
    "    \n",
    "    \n",
    "    vdf['lng'] = vdf.apply(lambda x: median_other['lng'] if (np.isnan(x['lng']) or (x['lng'] < geo_borders['minlng']) or (x['lng'] > geo_borders['maxlng'])) and (x['state_CA'] == 0)\n",
    "        else x['lng'], axis = 1)\n",
    "    vdf['lng'] = vdf.apply(lambda x: median_CA['lng'] if (np.isnan(x['lng']) or (x['lng'] < geo_borders['minlng']) or (x['lng'] > geo_borders['maxlng'])) and (x['state_CA'] == 1)\n",
    "        else x['lng'], axis = 1)\n",
    "    \n",
    "    vdf['HF_Lotsize'] = vdf.apply(lambda x: median_other['HF_Lotsize'] if (np.isnan(x['HF_Lotsize']) or (x['HF_Lotsize'] == 0)) and (x['state_CA'] == 0)        \n",
    "        else x['HF_Lotsize'], axis = 1)\n",
    "    vdf['HF_Lotsize'] = vdf.apply(lambda x: median_CA['HF_Lotsize'] if (np.isnan(x['HF_Lotsize']) or (x['HF_Lotsize'] == 0)) and (x['state_CA'] == 1)\n",
    "        else x['HF_Lotsize'], axis = 1)\n",
    "    \n",
    "    vdf['HF_YearBuilt'] = vdf.apply(lambda x: median_other['HF_YearBuilt'] \n",
    "                                    if (np.isnan(x['HF_YearBuilt']) or (x['HF_YearBuilt'] <= 1900) or (x['HF_YearBuilt'] > datetime.now().year + 10)) and (x['state_CA'] == 0)\n",
    "        else x['HF_YearBuilt'], axis = 1)\n",
    "    vdf['HF_YearBuilt'] = vdf.apply(lambda x: median_CA['HF_YearBuilt'] \n",
    "                                    if (np.isnan(x['HF_YearBuilt']) or (x['HF_YearBuilt'] <= 1900) or (x['HF_YearBuilt'] > datetime.now().year + 10)) and (x['state_CA'] == 1)\n",
    "        else x['HF_YearBuilt'], axis = 1)\n",
    "    \n",
    "    vdf['baths'] = vdf.apply(lambda x: x['sqft']*bath_sqft_coef if np.isnan(x['baths']) or (x['baths'] > x['sqft']*bath_sqft_border_coef[0]) else x['baths'], axis = 1)\n",
    "    \n",
    "    data_for_transform = vdf['sqft'].values.reshape((len(vdf), 1))\n",
    "    vdf['sqft'] = pd.DataFrame(sqft_q_trans.transform(data_for_transform), columns = ['sqft'], index=vdf.index)\n",
    "    \n",
    "    tvdf = vdf.copy()\n",
    "    tvdf = tvdf[['sqft', 'baths', 'lng', 'lat', 'SC_Rating_Mean', 'SC_Distance_Max', 'HF_YearBuilt', 'HF_Lotsize', 'propertyType_condo', 'state_CA', 'target']]\n",
    "    \n",
    "    #for col in tvdf.columns:\n",
    "    #    if col not in df_columns:\n",
    "    #        tvdf.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    for col in df_columns:\n",
    "        if col in tvdf.columns:\n",
    "            tvdf.drop(col, axis=1, inplace=True)\n",
    "            tvdf[col] = vdf[col]\n",
    "        else:\n",
    "            tvdf[col] = 0\n",
    "            \n",
    "    vdf = tvdf\n",
    "    \n",
    "    if 'target' in vdf.columns:\n",
    "        X = vdf.drop('target', axis=1)\n",
    "        y = vdf['target']\n",
    "    else:\n",
    "        X = vdf\n",
    "        y = 0\n",
    "    \n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    X = X[:, idx10_features]\n",
    "    #X = X[:, [0, 4, 10, 3, 9, 5, 8, 19, 23, 6]]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ax):\n",
    "    \"\"\"Получить предсказанеи модели\n",
    "\n",
    "    Args:\n",
    "        ndarray ax: признаки\n",
    "\n",
    "    Returns:\n",
    "        ndarray: предсказания\n",
    "    \"\"\"\n",
    "    return model.predict(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deviation(atrue, apred):\n",
    "    \"\"\"Получить отклонение предсказанного значения от истинного\n",
    "\n",
    "    Args:\n",
    "        float atrue: истинное значение\n",
    "        float apred: предсказанное значение\n",
    "    \"\"\"\n",
    "    if atrue > apred:\n",
    "        return \"{:02n} %\".format(round((1 - apred/atrue)*100)*(-1))\n",
    "    else:\n",
    "        return \"{:02n} %\".format(round((1 - atrue/apred)*100))\n",
    "\n",
    "def print_result(sd, y_pred, y_true):\n",
    "    t = PrettyTable(['State', 'City', 'Address', 'Sqft', 'Predicted', 'Real price (test)', 'Deviation'])\n",
    "    for idx, y in enumerate(y_pred):\n",
    "        y = np.exp(y)+1\n",
    "        yt = str_float_to_int(y_true.iloc[idx])\n",
    "        if (yt != np.nan) and (not np.isnan(yt)) and (yt > 0):\n",
    "            t.add_row([sd['state'].iloc[idx], sd['city'].iloc[idx], sd['street'].iloc[idx], sd['sqft'].iloc[idx], '${:0,.0f}'.format(y), '${:0,.0f}'.format(yt), get_deviation(yt, y)])\n",
    "        else:\n",
    "            t.add_row([sd['state'].iloc[idx], sd['city'].iloc[idx], sd['street'].iloc[idx], sd['sqft'].iloc[idx], '${:0,.0f}'.format(y), '-', '-'])\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод прогноза\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def model_predict():\n",
    "    features = request.json\n",
    "    jdata = json.loads(features)\n",
    "    dfr = pd.DataFrame(jdata)\n",
    "    df = dfr.T\n",
    "\n",
    "    X, y = get_x_y(df)\n",
    "    yp = np.exp(predict(X)) + 1\n",
    "\n",
    "    return {'prediction': yp.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Старт сервиса\n",
    "if __name__ == '__main__':\n",
    "    app.run('0.0.0.0', 5000)\n",
    "    #from waitress import serve\n",
    "    #serve(app, host=\"0.0.0.0\", port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
