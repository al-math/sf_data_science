{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка модели в продакшен-формате\n",
    "Данный модуль является техническим и служит для проверки выгруженной модели и вспомогательных данных на работоспособность и корректность прогнозов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Примечание 1:\n",
    "Для тестирования в модель подаётся dataframe из 10 ключевых признаков и target-признака, преобразованный в json-формат.</br>\n",
    "Если в данных target-признак равен 0, то считается, что его нет (боевое использование) и в этом случае модель выдаёт только прогноз без оценки его точности."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Примечание 2:\n",
    "Можно было бы все функции и класс, использованные при обработке данных и подборе модели, выгрузить в отдельный модуль-библиотеку и не копировать код, но в этом случае снизится читабельность и понимание блока с подбором модели."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Примечание 3:\n",
    "Благодаря тому, что подаваемые данные содержат существенно меньше объектов для оценки, мы можем позволить себе определять географические координаты с использованием адреса объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "import ast\n",
    "#from Model.ms_func import Dumper\n",
    "import pickle\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "from prettytable import PrettyTable\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Класс для чтения сохранённой модели и вспомогательных данных\n",
    "class Dumper():  \n",
    "    def __init__(self, model_dir=\"Model/\"):  \n",
    "        self.model_dir = model_dir  \n",
    "          \n",
    "    # сохраняет объект\n",
    "    def dump(self, data, filename):  \n",
    "        with open(self.get_file_name(filename), 'wb') as file:  \n",
    "            pickle.dump(data, file)  \n",
    "              \n",
    "    # загружает объект\n",
    "    def load(self, filename):  \n",
    "        file_name = path.join(self.model_dir, filename + \".pkl\")   \n",
    "        with open(file_name, 'rb') as file:  \n",
    "            sets = pickle.load(file)  \n",
    "        return sets  \n",
    "          \n",
    "    # возвращает полное имя файла\n",
    "    def get_file_name(self, filename):   \n",
    "        return path.join(self.model_dir, filename + \".pkl\")\n",
    "    \n",
    "app = Nominatim(user_agent=\"tutorial\")\n",
    "    \n",
    "def get_loc(street, city, zipcode):\n",
    "    \"\"\"Получаем географические координаты по адресу, городу, почтовому индексу\n",
    "\n",
    "    Args:\n",
    "        street (string): адрес\n",
    "        city (string): город\n",
    "        zipcode (string): почтовый индекс\n",
    "\n",
    "    Returns:\n",
    "        tuple (float lat, float lon): географические координаты.\n",
    "    \"\"\"\n",
    "    answ = (np.nan, np.nan)\n",
    "    if street == None:\n",
    "        street = ''\n",
    "    if city == None:\n",
    "        city = ''\n",
    "    if zipcode == None:\n",
    "        zipcode = ''\n",
    "    street = str(street).strip()\n",
    "    city = str(city).strip()\n",
    "    zipcode = str(zipcode).strip()\n",
    "    haserror = False\n",
    "    \n",
    "    try:\n",
    "        location = app.geocode(street + ' ' + city).raw\n",
    "        answ = (location['lat'], location['lon'])\n",
    "    except Exception:\n",
    "        haserror = True\n",
    "        \n",
    "    if haserror == True:\n",
    "        try:\n",
    "            location = app.geocode(zipcode).raw\n",
    "            answ = (location['lat'], location['lon'])\n",
    "        except Exception:\n",
    "            answ = (np.nan, np.nan)\n",
    "    \n",
    "    return answ\n",
    "\n",
    "def GetFromHomeFactsList(AStr):\n",
    "    \"\"\"Получить информацию из записи в колонке homeFacts\n",
    "\n",
    "    Args:\n",
    "        string: строка из колокни homeFacts.\n",
    "\n",
    "    Returns:\n",
    "        list: значения свойств: 'Year built', 'Remodeled year', 'Heating', 'Cooling', 'Parking', 'lotsize', 'Price/sqft'\n",
    "    \"\"\"\n",
    "    answ = [None, None, None, None, None, None, None]\n",
    "    labs = ['Year built', 'Remodeled year', 'Heating', 'Cooling', 'Parking', 'lotsize', 'Price/sqft']\n",
    "    try:\n",
    "        lst = ast.literal_eval(AStr)['atAGlanceFacts']\n",
    "        answ = []\n",
    "        for l in labs:\n",
    "            fnd = False\n",
    "            try:\n",
    "                for val in lst:\n",
    "                    if val['factLabel'] == l:\n",
    "                        answ.append(val['factValue'])\n",
    "                        fnd = True\n",
    "                        break\n",
    "                if fnd == False:\n",
    "                    answ.append(None)\n",
    "            except Exception:\n",
    "                answ.append(None)\n",
    "    except Exception:\n",
    "        return answ\n",
    "    return answ\n",
    "\n",
    "def GetFromSchoolList(AStr):\n",
    "    \"\"\"Получить информацию из записи в колонке schools\n",
    "\n",
    "    Args:\n",
    "        string: строка из колокни schools.\n",
    "\n",
    "    Returns:\n",
    "        list: значения свойств: 'rating', 'data'.'Distance', 'data'.'Grades', 'name'\n",
    "    \"\"\"\n",
    "    answ = [[None], [None], [None], [None]]\n",
    "    labs1lvl = ['rating', 'data', 'name']\n",
    "    labs2lvl = ['Distance', 'Grades']\n",
    "    try:\n",
    "        lst = ast.literal_eval(AStr)[0]\n",
    "        answ = []\n",
    "        for l in labs1lvl:\n",
    "            try:\n",
    "                if l == 'data':\n",
    "                    try:\n",
    "                        answ.append(lst[l]['Distance'])    \n",
    "                    except Exception:\n",
    "                        answ.append([None])\n",
    "                    try:\n",
    "                        answ.append(lst[l]['Grades'])    \n",
    "                    except Exception:\n",
    "                        answ.append([None])\n",
    "                else:\n",
    "                    answ.append(lst[l])  \n",
    "            except Exception:\n",
    "                answ.append([None])\n",
    "    except Exception:\n",
    "        return answ\n",
    "    return answ\n",
    "\n",
    "def strIntersection(s1, s2):\n",
    "    \"\"\"Служебная функция для того, чтобы оставлять в строке только те символы, которые соответствуют маске\n",
    "\n",
    "    Args:\n",
    "        string: s1 исходная строка.\n",
    "        string: s2 маска.\n",
    "\n",
    "    Returns:\n",
    "        string: исходная строка после применения маски\n",
    "    \"\"\"\n",
    "    out = \"\"\n",
    "    for c in s1:\n",
    "        if c in s2:\n",
    "            out += c\n",
    "    return out\n",
    "\n",
    "def MaxMinMeanDistance(Alst):\n",
    "    \"\"\"Функция для определения минимального, максимального и среднего расстояния до учебного заведения\n",
    "\n",
    "    Args:\n",
    "        list: Alst - список из расстояний.\n",
    "\n",
    "    Returns:\n",
    "        list: минимальное, максимальное и среднее расстояние до учебного заведения\n",
    "    \"\"\"\n",
    "    res = [np.nan, np.nan, np.nan]\n",
    "    dcount = 0\n",
    "    dsum = 0.0\n",
    "    dMax = 0.0\n",
    "    dMin = np.inf\n",
    "    mask = '0123456789.'\n",
    "    for elm in Alst:\n",
    "        elm = strIntersection(elm, mask)\n",
    "        if elm != '':\n",
    "            fElm = float(elm)\n",
    "            dsum += fElm\n",
    "            if fElm < dMin:\n",
    "                dMin = fElm\n",
    "            if fElm > dMax:\n",
    "                dMax = fElm\n",
    "            dcount += 1\n",
    "    if dcount > 0:\n",
    "        res = [dMax, dMin, dsum/dcount]\n",
    "    return res\n",
    "\n",
    "def MaxMinMeanRating(Alst):\n",
    "    \"\"\"Функция для определения минимального, максимального и среднего рейтинга учебного заведения\n",
    "\n",
    "    Args:\n",
    "        list: Alst - список рейтингов.\n",
    "\n",
    "    Returns:\n",
    "        list: минимальное, максимальное и среднее значение рейтинга учебного заведения\n",
    "    \"\"\"\n",
    "    res = [np.nan, np.nan, np.nan]\n",
    "    dcount = 0\n",
    "    dsum = 0.0\n",
    "    dMax = 0.0\n",
    "    dMin = np.inf\n",
    "    mask = '0123456789/'\n",
    "    for elm in Alst:\n",
    "        elm = strIntersection(elm, mask)\n",
    "        elm = elm.replace('/10', '')\n",
    "        if elm != '':\n",
    "            fElm = float(elm)\n",
    "            dsum += fElm\n",
    "            if fElm < dMin:\n",
    "                dMin = fElm\n",
    "            if fElm > dMax:\n",
    "                dMax = fElm\n",
    "            dcount += 1\n",
    "    if dcount > 0:\n",
    "        res = [dMax/10, dMin/10, dsum/dcount/10]\n",
    "    return res\n",
    "\n",
    "def str_to_float(aStr):\n",
    "    \"\"\"Функция для преобразования строки в действительное число\n",
    "\n",
    "    Args:\n",
    "        string: aStr - возможное число в строковом представлении\n",
    "\n",
    "    Returns:\n",
    "        float: действительное число или nan, если не удалось совершить преобразование\n",
    "    \"\"\"\n",
    "    if aStr == None:\n",
    "        return np.nan\n",
    "    aStr = strIntersection(str(aStr), '-0123456789.')\n",
    "    if aStr == '':\n",
    "        return np.nan\n",
    "    aStr = aStr.replace('..', '.')\n",
    "    aStr = aStr.replace('--', '-')\n",
    "    if aStr == '.':\n",
    "        return np.nan\n",
    "    if aStr[len(aStr) - 1] == '.':\n",
    "        aStr = aStr[0:len(aStr)-1]\n",
    "    try:\n",
    "        return float(aStr)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def str_float_to_int(aStr):\n",
    "    \"\"\"Функция для преобразования строки в целое число\n",
    "\n",
    "    Args:\n",
    "        string: aStr - возможное число в строковом представлении\n",
    "\n",
    "    Returns:\n",
    "        float: целое число или nan, если не удалось совершить преобразование\n",
    "    \"\"\"\n",
    "    aFlt = str_to_float(aStr)\n",
    "    try:\n",
    "        return int(round(aFlt))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    \n",
    "def ColToLow(df, colname):\n",
    "    \"\"\"Функция для приведения текстового признака к нижнему регистру и только базовым символам\n",
    "\n",
    "    Args:\n",
    "        dataframe: df - исходный датафрейм\n",
    "        string: colname - признак\n",
    "\n",
    "    Returns:\n",
    "        преобразует признак в исходном датафрейме\n",
    "    \"\"\"\n",
    "    mask = 'qwertyuiopasdfghjklzxcvbnm1234567890'\n",
    "    df[colname] = df[colname].str.lower()\n",
    "    df[colname] = df[colname].apply(lambda x: strIntersection(str(x), mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumper = Dumper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель\n",
    "model = dumper.load('model')\n",
    "# граничный коэффициент ванн на квадратный фут\n",
    "bath_sqft_border_coef = dumper.load('bath_sqft_border_coef')\n",
    "# среднее количество ванн на квадратный фут\n",
    "bath_sqft_coef = dumper.load('bath_sqft_coef')\n",
    "# географический прямоугольник, ограничивающий координаты объектов в США\n",
    "geo_borders = dumper.load('geo_borders')\n",
    "# медианные значения ключевых признаков в Калифонии (CA)\n",
    "median_CA = dumper.load('median_CA')\n",
    "# медианные значения ключевых признаков в остальных штатах\n",
    "median_other = dumper.load('median_other')\n",
    "# преобразователь масштаба\n",
    "scaler = dumper.load('scaler')\n",
    "# преобразователь QuantileTransformer\n",
    "sqft_q_trans = dumper.load('sqft_q_trans')\n",
    "# список колонок (и их порядок), которые участвуют в финальных признаках\n",
    "df_columns = dumper.load('df_columns')\n",
    "# порядок сокращённого набора признаков\n",
    "idx10_features = dumper.load('idx10_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(adf):\n",
    "    \"\"\"Преобразовать входной dataframe в набор, котрый можно подать на вход модели\n",
    "       Преобразователь преобразкет тип, заполняет, кодирует, масштабирует признаки аналогично тому, как это происходило при подготовке датасета модели\n",
    "\n",
    "    Args:\n",
    "        dataframe: датафрейм для прогнозирования.\n",
    "\n",
    "    Returns:\n",
    "        ndarray X: признаки, подготовленные к передаче в модель\n",
    "        series y: целевой признак (для проверки); если использование \"боевое\", то передать в исходном dataframe 0\n",
    "    \"\"\"\n",
    "    vdf = adf.copy()    \n",
    "      \n",
    "    vdf['SC_List'] = vdf['schools'].apply(lambda x: GetFromSchoolList(x))\n",
    "\n",
    "    vdf['SC_Distance'] = vdf['SC_List'].apply(lambda x: x[1])\n",
    "    vdf['SC_Distance_Lst'] = vdf['SC_Distance'].apply(lambda x: MaxMinMeanDistance(x))\n",
    "    vdf['SC_Distance_Max'] = vdf['SC_Distance_Lst'].apply(lambda x: x[0])\n",
    "    \n",
    "    vdf['SC_Rating'] = vdf['SC_List'].apply(lambda x: x[0])    \n",
    "    vdf['SC_Rating_Lst'] = vdf['SC_Rating'].apply(lambda x: MaxMinMeanRating(x))\n",
    "    vdf['SC_Rating_Mean'] = vdf['SC_Rating_Lst'].apply(lambda x: x[2])\n",
    "    \n",
    "    vdf['lat'], vdf['lng'] = zip(*vdf.apply(lambda x: get_loc(x['street'], x['city'], x['zipcode']), axis = 1))\n",
    "    vdf['lat'] = vdf['lat'].apply(lambda x: str_to_float(x))\n",
    "    vdf['lng'] = vdf['lng'].apply(lambda x: str_to_float(x))\n",
    "    \n",
    "    vdf['sqft'] = vdf['sqft'].apply(lambda x: str_float_to_int(x))\n",
    "    vdf['baths'] = vdf['baths'].apply(lambda x: str_float_to_int(x))\n",
    "    \n",
    "    vdf['HF_List'] = vdf['homeFacts'].apply(lambda x: GetFromHomeFactsList(x))\n",
    "    vdf['HF_YearBuilt'] = vdf['HF_List'].apply(lambda x: x[0])\n",
    "    vdf['HF_Lotsize'] = vdf['HF_List'].apply(lambda x: x[5])\n",
    "    vdf['HF_YearBuilt'] = vdf['HF_YearBuilt'].apply(lambda x: str_float_to_int(x))\n",
    "    vdf['HF_Lotsize'] = vdf['HF_Lotsize'].apply(lambda x: str_float_to_int(x))\n",
    "    vdf['target'] = vdf['target'].apply(lambda x: str_float_to_int(x))\n",
    "    \n",
    "    ColToLow(vdf, 'propertyType')\n",
    "    vdf['propertyType_condo'] = vdf['propertyType'].apply(lambda x: 1 if x == 'condo' else 0)\n",
    "    \n",
    "    vdf['state_CA'] = vdf['state'].apply(lambda x: 1 if x == 'CA' else 0)\n",
    "    \n",
    "    vdf['SC_Distance_Max'] = vdf.apply(lambda x: median_other['SC_Distance_Max'] if (np.isnan(x['SC_Distance_Max']) or (x['SC_Distance_Max'] == 0)) and (x['state_CA'] == 0)        \n",
    "        else x['SC_Distance_Max'], axis = 1)\n",
    "    vdf['SC_Distance_Max'] = vdf.apply(lambda x: median_CA['SC_Distance_Max'] if (np.isnan(x['SC_Distance_Max']) or (x['SC_Distance_Max'] == 0)) and (x['state_CA'] == 1)\n",
    "        else x['SC_Distance_Max'], axis = 1)\n",
    "    \n",
    "    vdf['SC_Rating_Mean'] = vdf.apply(lambda x: median_other['SC_Rating_Mean'] if (np.isnan(x['SC_Rating_Mean']) or (x['SC_Rating_Mean'] == 0)) and (x['state_CA'] == 0)        \n",
    "        else x['SC_Rating_Mean'], axis = 1)\n",
    "    vdf['SC_Rating_Mean'] = vdf.apply(lambda x: median_CA['SC_Rating_Mean'] if (np.isnan(x['SC_Rating_Mean']) or (x['SC_Rating_Mean'] == 0)) and (x['state_CA'] == 1)\n",
    "        else x['SC_Rating_Mean'], axis = 1)\n",
    "    \n",
    "    vdf['lat'] = vdf.apply(lambda x: median_other['lat'] if (np.isnan(x['lat']) or (x['lat'] < geo_borders['minlat']) or (x['lat'] > geo_borders['maxlat'])) and (x['state_CA'] == 0)\n",
    "        else x['lat'], axis = 1)\n",
    "    vdf['lat'] = vdf.apply(lambda x: median_CA['lat'] if (np.isnan(x['lat']) or (x['lat'] < geo_borders['minlat']) or (x['lat'] > geo_borders['maxlat'])) and (x['state_CA'] == 1)\n",
    "        else x['lat'], axis = 1)\n",
    "    \n",
    "    \n",
    "    vdf['lng'] = vdf.apply(lambda x: median_other['lng'] if (np.isnan(x['lng']) or (x['lng'] < geo_borders['minlng']) or (x['lng'] > geo_borders['maxlng'])) and (x['state_CA'] == 0)\n",
    "        else x['lng'], axis = 1)\n",
    "    vdf['lng'] = vdf.apply(lambda x: median_CA['lng'] if (np.isnan(x['lng']) or (x['lng'] < geo_borders['minlng']) or (x['lng'] > geo_borders['maxlng'])) and (x['state_CA'] == 1)\n",
    "        else x['lng'], axis = 1)\n",
    "    \n",
    "    vdf['HF_Lotsize'] = vdf.apply(lambda x: median_other['HF_Lotsize'] if (np.isnan(x['HF_Lotsize']) or (x['HF_Lotsize'] == 0)) and (x['state_CA'] == 0)        \n",
    "        else x['HF_Lotsize'], axis = 1)\n",
    "    vdf['HF_Lotsize'] = vdf.apply(lambda x: median_CA['HF_Lotsize'] if (np.isnan(x['HF_Lotsize']) or (x['HF_Lotsize'] == 0)) and (x['state_CA'] == 1)\n",
    "        else x['HF_Lotsize'], axis = 1)\n",
    "    \n",
    "    vdf['HF_YearBuilt'] = vdf.apply(lambda x: median_other['HF_YearBuilt'] \n",
    "                                    if (np.isnan(x['HF_YearBuilt']) or (x['HF_YearBuilt'] <= 1900) or (x['HF_YearBuilt'] > datetime.now().year + 10)) and (x['state_CA'] == 0)\n",
    "        else x['HF_YearBuilt'], axis = 1)\n",
    "    vdf['HF_YearBuilt'] = vdf.apply(lambda x: median_CA['HF_YearBuilt'] \n",
    "                                    if (np.isnan(x['HF_YearBuilt']) or (x['HF_YearBuilt'] <= 1900) or (x['HF_YearBuilt'] > datetime.now().year + 10)) and (x['state_CA'] == 1)\n",
    "        else x['HF_YearBuilt'], axis = 1)\n",
    "    \n",
    "    vdf['baths'] = vdf.apply(lambda x: x['sqft']*bath_sqft_coef if np.isnan(x['baths']) or (x['baths'] > x['sqft']*bath_sqft_border_coef[0]) else x['baths'], axis = 1)\n",
    "    \n",
    "    data_for_transform = vdf['sqft'].values.reshape((len(vdf), 1))\n",
    "    vdf['sqft'] = pd.DataFrame(sqft_q_trans.transform(data_for_transform), columns = ['sqft'], index=vdf.index)\n",
    "    \n",
    "    tvdf = vdf.copy()\n",
    "    tvdf = tvdf[['sqft', 'baths', 'lng', 'lat', 'SC_Rating_Mean', 'SC_Distance_Max', 'HF_YearBuilt', 'HF_Lotsize', 'propertyType_condo', 'state_CA', 'target']]\n",
    "    \n",
    "    #for col in tvdf.columns:\n",
    "    #    if col not in df_columns:\n",
    "    #        tvdf.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    for col in df_columns:\n",
    "        if col in tvdf.columns:\n",
    "            tvdf.drop(col, axis=1, inplace=True)\n",
    "            tvdf[col] = vdf[col]\n",
    "        else:\n",
    "            tvdf[col] = 0\n",
    "            \n",
    "    vdf = tvdf\n",
    "    \n",
    "    X = vdf.drop('target', axis=1)\n",
    "    y = vdf['target']\n",
    "    \n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    X = X[:, idx10_features]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ax):\n",
    "    \"\"\"Получить предсказанеи модели\n",
    "\n",
    "    Args:\n",
    "        ndarray ax: признаки\n",
    "\n",
    "    Returns:\n",
    "        ndarray: предсказания\n",
    "    \"\"\"\n",
    "    return model.predict(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deviation(atrue, apred):\n",
    "    \"\"\"Получить отклонение предсказанного значения от истинного\n",
    "\n",
    "    Args:\n",
    "        float atrue: истинное значение\n",
    "        float apred: предсказанное значение\n",
    "\n",
    "    Returns:\n",
    "        string: строковое представление отклоения\n",
    "    \"\"\"\n",
    "    if atrue > apred:\n",
    "        return \"{:02n} %\".format(round((1 - apred/atrue)*100)*(-1))\n",
    "    else:\n",
    "        return \"{:02n} %\".format(round((1 - atrue/apred)*100))\n",
    "\n",
    "def print_result(sd, y_pred, y_true):\n",
    "    \"\"\"Печать результата в красивой табличной форме\n",
    "\n",
    "    Args:\n",
    "        dataframe sd: dataframe из признаков\n",
    "        float y_pred: истинное значение\n",
    "        float y_true: предсказанное значение\n",
    "    \"\"\"\n",
    "    t = PrettyTable(['State', 'City', 'Address', 'Sqft', 'Predicted', 'Real price (test)', 'Deviation'])\n",
    "    for idx, y in enumerate(y_pred):\n",
    "        y = np.exp(y)+1\n",
    "        yt = str_float_to_int(y_true.iloc[idx])\n",
    "        if (yt != np.nan) and (not np.isnan(yt)) and (yt > 0):\n",
    "            t.add_row([sd['state'].iloc[idx], sd['city'].iloc[idx], sd['street'].iloc[idx], sd['sqft'].iloc[idx], '${:0,.0f}'.format(y), '${:0,.0f}'.format(yt), get_deviation(yt, y)])\n",
    "        else:\n",
    "            t.add_row([sd['state'].iloc[idx], sd['city'].iloc[idx], sd['street'].iloc[idx], sd['sqft'].iloc[idx], '${:0,.0f}'.format(y), '-', '-'])\n",
    "    print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка.<br/>\n",
    "Выберем 10 случайных записей из данных (ключевые признаки), исключим из них данные с нулевой площадью, спрогнозируем цену и посмотрим на точность предсказания.<br/>\n",
    "В среднем точность не должна выходить за пределы характеристик финальной модели (21.33%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------------+------------+-----------+-------------------+-----------+\n",
      "| State |       City       |         Address          |    Sqft    | Predicted | Real price (test) | Deviation |\n",
      "+-------+------------------+--------------------------+------------+-----------+-------------------+-----------+\n",
      "|   CA  | Huntington Beach |      8282 Darsy Dr       | 1,346 sqft |  $804,021 |      $773,287     |    04 %   |\n",
      "|   NC  |     Gastonia     |     918 S Miller St      | 1,342 sqft |  $204,625 |      $175,247     |    14 %   |\n",
      "|   CA  |      Irvine      |     21-414 Gramercy      | 1,552 sqft |  $655,837 |      $639,000     |    03 %   |\n",
      "|   AZ  |      Peoria      |   9526 W Park View Ln    |   3,097    |  $458,156 |      $427,990     |    07 %   |\n",
      "|   TX  |    Fort Worth    |     4232 Sandage Ave     |  765 sqft  |  $179,715 |      $179,900     |    00 %   |\n",
      "|   FL  |   Jacksonville   |      2602 Rogero Rd      | 1,196 sqft |  $118,449 |      $110,000     |    07 %   |\n",
      "|   WA  |     Seattle      | 2768 SW Holden St UNIT 2 | 1,942 sqft |  $434,460 |      $725,000     |   -40 %   |\n",
      "|   TX  |     Pasadena     |    1308 Carpenter Ave    |    2483    |  $208,835 |      $219,990     |    -5 %   |\n",
      "|   NC  |    High Point    |    2669 Lamplight Cir    | 3,391 sqft |  $394,743 |      $335,000     |    15 %   |\n",
      "+-------+------------------+--------------------------+------------+-----------+-------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Выберем случайную строку отсчёта\n",
    "ridx = random.randint(0, data.shape[0] - 10)\n",
    "# Выберем 10 строк признаков, начиная с выбранной строки\n",
    "df = data[ridx:ridx + 10]\n",
    "# Исключим строки с некорректной площадью объекта\n",
    "df = df[((df['sqft'].isna() != True) & (df['sqft'] != '0'))]\n",
    "# Получим подготовленные признаки для передачи в модель\n",
    "X, y = get_x_y(df)\n",
    "# Вызовем модель\n",
    "yp = predict(X)\n",
    "# Выведем предсказание (и оценку точности в режиме проверки)\n",
    "print_result(df, yp, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итог\n",
    "Выгруженная модель работает корректно, можно оформлять в виде сервиса"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
